{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c56bebe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                City1                             City2  \\\n",
      "3399        presidente castelo branco        presidente castello branco   \n",
      "627            sao joao do pau d'alho             sao joao do pau dalho   \n",
      "3135            figueir√≥polis d'oeste              figueir√≥polis doeste   \n",
      "3032          nova brasilandia doeste          nova brasilandia d oeste   \n",
      "3137  vila bela da santssima trindade  vila bela da sant√≠ssima trindade   \n",
      "...                               ...                               ...   \n",
      "1783           sao francisco do conde            sao francisco do oeste   \n",
      "1781           s√£o sebasti√£o do pass√©              s√£o sebasti√£o do ca√≠   \n",
      "1780           s√£o sebasti√£o do passe              s√£o sebasti√£o do ca√≠   \n",
      "1778           sao sebastiao do passe              sao sebastiao do cai   \n",
      "3664                          ciriaco                           cir√≠aco   \n",
      "\n",
      "      Similarity  \n",
      "3399          98  \n",
      "627           98  \n",
      "3135          98  \n",
      "3032          98  \n",
      "3137          98  \n",
      "...          ...  \n",
      "1783          86  \n",
      "1781          86  \n",
      "1780          86  \n",
      "1778          86  \n",
      "3664          86  \n",
      "\n",
      "[3665 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('D:\\olist_geolocation_dataset.csv')\n",
    "\n",
    "# Drop duplicates for performance\n",
    "unique_cities = df['geolocation_city'].dropna().unique()\n",
    "\n",
    "# Create list to store possible mistyped pairs\n",
    "similar_pairs = []\n",
    "\n",
    "# Compare each city with others\n",
    "for i, city in enumerate(unique_cities):\n",
    "    for compare_city in unique_cities[i+1:]:\n",
    "        score = fuzz.ratio(city.lower(), compare_city.lower())\n",
    "        if 85 < score < 100:  # not identical but very close\n",
    "            similar_pairs.append((city, compare_city, score))\n",
    "\n",
    "# Convert to DataFrame\n",
    "similar_df = pd.DataFrame(similar_pairs, columns=['City1', 'City2', 'Similarity'])\n",
    "\n",
    "# View suspicious pairs\n",
    "print(similar_df.sort_values(by='Similarity', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "525cc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 987, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 1433, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 703, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: server closed the connection unexpectedly\n",
      "\tThis probably means the server terminated abnormally\n",
      "\tbefore or while processing the request.\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 987, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 1433, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 703, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: server closed the connection unexpectedly\n",
      "\tThis probably means the server terminated abnormally\n",
      "\tbefore or while processing the request.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully corrected similar city names in geolocation_city.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Step 1: Connect to PostgreSQL\n",
    "username = 'postgres'\n",
    "password = 'deepakbisht69'\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "database = 'e-commerce project'\n",
    "\n",
    "engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{database}')\n",
    "conn = engine.connect()\n",
    "\n",
    "# Step 2: Load geolocation data\n",
    "df = pd.read_sql(\"SELECT geo_id, geolocation_city FROM olist_geolocation\", conn)\n",
    "df['geolocation_city_clean'] = df['geolocation_city'].str.lower().str.strip()\n",
    "\n",
    "# Step 3: Get frequency of each city\n",
    "city_freq = df['geolocation_city_clean'].value_counts().reset_index()\n",
    "city_freq.columns = ['city', 'count']\n",
    "\n",
    "# Step 4: Identify similar cities\n",
    "from itertools import combinations\n",
    "similar_map = {}\n",
    "\n",
    "city_list = city_freq['city'].tolist()\n",
    "\n",
    "for city1, city2 in combinations(city_list, 2):\n",
    "    score = fuzz.ratio(city1, city2)\n",
    "    if 95 < score < 100:\n",
    "        # Choose the more frequent one as the correct name\n",
    "        count1 = city_freq[city_freq['city'] == city1]['count'].values[0]\n",
    "        count2 = city_freq[city_freq['city'] == city2]['count'].values[0]\n",
    "        correct = city1 if count1 >= count2 else city2\n",
    "        wrong = city2 if count1 >= count2 else city1\n",
    "        similar_map[wrong] = correct\n",
    "\n",
    "# Step 5: Replace wrong values with correct ones\n",
    "df['geolocation_city_corrected'] = df['geolocation_city_clean'].replace(similar_map)\n",
    "\n",
    "# Step 6: Update PostgreSQL using geo_id\n",
    "from sqlalchemy.sql import text\n",
    "\n",
    "with engine.begin() as connection:\n",
    "    for index, row in df.iterrows():\n",
    "        connection.execute(\n",
    "            text(\"\"\"\n",
    "                UPDATE olist_geolocation\n",
    "                SET geolocation_city = :new_val\n",
    "                WHERE geo_id = :geo_id\n",
    "            \"\"\"),\n",
    "            {'new_val': row['geolocation_city_corrected'], 'geo_id': row['geo_id']}\n",
    "        )\n",
    "\n",
    "print(\"‚úÖ Successfully corrected similar city names in geolocation_city.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06fe1093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Total possible typo/conflict pairs remaining: 358\n",
      "           City1        City2  Similarity\n",
      "179   itambaraca    itamaraca          95\n",
      "138   catanduvas    catanduva          95\n",
      "185  petrolandia   perolandia          95\n",
      "184   fronteiras    fronteira          95\n",
      "164   montenegro  monte negro          95\n",
      "162    alexandra   alexandria          95\n",
      "159   charqueada  charqueadas          95\n",
      "149    pau darco   pau d arco          95\n",
      "145  itainopolis   itaiopolis          95\n",
      "134   cearamirim  ceara mirim          95\n",
      "38    crisopolis  cristopolis          95\n",
      "126  materlandia   matelandia          95\n",
      "125   palmeirais    palmeiras          95\n",
      "100   gameleiras    gameleira          95\n",
      "97   jaboticabal   jaboticaba          95\n",
      "94   rio bracnco   rio branco          95\n",
      "84    lagoa nova  alagoa nova          95\n",
      "78     alagoinha   alagoinhas          95\n",
      "193   mogi guacu    mogiguacu          95\n",
      "205  paragominas   aragominas          95\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# -------------------------------\n",
    "# 1. CONNECT TO POSTGRESQL\n",
    "# -------------------------------\n",
    "username = 'postgres'\n",
    "password = 'deepakbisht69'\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "database = 'e-commerce project'\n",
    "\n",
    "engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{database}')\n",
    "conn = engine.connect()\n",
    "\n",
    "# -------------------------------\n",
    "# 2. LOAD CLEANED COLUMN\n",
    "# -------------------------------\n",
    "df = pd.read_sql(\"SELECT DISTINCT geolocation_city FROM olist_geolocation\", conn)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. PREPARE FOR FUZZY MATCHING\n",
    "# -------------------------------\n",
    "df['cleaned'] = df['geolocation_city'].str.strip().str.lower()\n",
    "unique_cities = df['cleaned'].dropna().unique()\n",
    "\n",
    "# -------------------------------\n",
    "# 4. FIND SIMILARITY > 90\n",
    "# -------------------------------\n",
    "from itertools import combinations\n",
    "similar_pairs = []\n",
    "\n",
    "for city1, city2 in combinations(unique_cities, 2):\n",
    "    score = fuzz.ratio(city1, city2)\n",
    "    if 90 < score < 100:  # Similar but not same\n",
    "        similar_pairs.append((city1, city2, score))\n",
    "\n",
    "# -------------------------------\n",
    "# 5. SHOW RESULTS\n",
    "# -------------------------------\n",
    "similar_df = pd.DataFrame(similar_pairs, columns=['City1', 'City2', 'Similarity'])\n",
    "similar_df = similar_df.sort_values(by='Similarity', ascending=False)\n",
    "\n",
    "print(f\"üîç Total possible typo/conflict pairs remaining: {len(similar_df)}\")\n",
    "print(similar_df.head(20))  # View top suspicious ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "848e7a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Suspicious rows with repeated phrases:\n",
      "\n",
      " geo_id                     geolocation_city\n",
      " 998244 rio de janeiro rio de janeiro brasil\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection info\n",
    "db_name = \"e-commerce project\"\n",
    "username = \"postgres\"\n",
    "password = \"deepakbisht69\"  # Replace with your password\n",
    "host = \"localhost\"\n",
    "port = \"5432\"\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "engine = create_engine(f\"postgresql+psycopg2://{username}:{password}@{host}:{port}/{db_name}\")\n",
    "conn = engine.connect()\n",
    "\n",
    "# Read geolocation_city column from table\n",
    "df = pd.read_sql(\"SELECT geo_id, geolocation_city FROM olist_geolocation\", conn)\n",
    "\n",
    "# Function to detect repeated word sequences\n",
    "def has_repeated_phrase(city):\n",
    "    if pd.isnull(city):\n",
    "        return False\n",
    "    words = city.lower().split()\n",
    "    for i in range(len(words) - 2):  # Check for 2 or 3 word phrases\n",
    "        phrase = ' '.join(words[i:i+2])\n",
    "        if phrase and city.lower().count(phrase) > 1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Filter rows with suspicious repeats\n",
    "df['has_repeat'] = df['geolocation_city'].apply(has_repeated_phrase)\n",
    "repeated_df = df[df['has_repeat']]\n",
    "\n",
    "# Display suspicious rows\n",
    "print(\"üîç Suspicious rows with repeated phrases:\\n\")\n",
    "print(repeated_df[['geo_id', 'geolocation_city']].to_string(index=False))\n",
    "\n",
    "# Optional: Save to CSV for manual review\n",
    "# repeated_df.to_csv(\"repeated_cities_check.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
